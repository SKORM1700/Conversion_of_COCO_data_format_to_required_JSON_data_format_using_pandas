# -*- coding: utf-8 -*-
"""Final_Conversion_of_COCO_data_format_to_JSON_data_format_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LNOkAlLBauZlnIEd-tQcIKnHMlp1L4q8

# Present work deals with the conversion of COCO data format to JSON data format

## Downloading the file and loading it
"""

#Importing the python json library
import json
def read_file(file_path):
#Reading the content of the file that have data in COCO format using 'with open'
#Notice, the file is opened in 'r' mode to read the content of the file
    with open (file_path,'r') as f:
        data=f.read()

#Using json.loads to parse the data into json format, this will create a dictionary
    final_data=json.loads(data)
    return final_data

"""# function to create image DataFrame"""

#importing pandas as pd
import pandas as pd

def images_data(final_data):
    #using 'json_normalize' to flatten semi-structured JSON data into a tabular format (DataFrame), to make it easier to analyze and work with the data
    #Extracting the 'images' data only
    images_data=pd.json_normalize(final_data,"images")

    #printing the intial five rows using head() function
    # images_data.head()

    #Extracting the 'id' and 'file_name' columns from the 'images_data' DataFrame as per the requirements
    images_data_final=images_data[["id","file_name"]]

    #Converting the "id" column data type to "object"
    images_data_final["id"]=images_data_final["id"].astype(object)

    #printing the intial five rows using head() function
    images_data_final.head()

    return images_data_final

"""# function to create annotations DataFrame"""

def annotation_data(final_data):
    #using 'json_normalize' to flatten semi-structured JSON data into a tabular format (DataFrame), to make it easier to analyze and work with the data
    #Extracting the 'annotations' data only
    annotations_data=pd.json_normalize(final_data,"annotations")

    #printing the intial five rows using head() function
    # annotations_data.head()

    #Extracting the "category_id","image_id", and "bbox" columns from the 'annotation_data' DataFrame as per the requirements
    annotations_data_final=annotations_data[["category_id","image_id","bbox"]]

    #printing the intial five rows using head() function
    # annotations_data_final.head()

    return annotations_data_final

"""# function to create categories DataFrame"""

def categories_data(final_data):
    #using 'json_normalize' to flatten semi-structured JSON data into a tabular format (DataFrame), to make it easier to analyze and work with the data
    #Extracting the 'categories' data only
    categories_data=pd.json_normalize(final_data,"categories")

    #printing the intial five rows using head() function
    # categories_data.head()

    #Extracting the "id", and "name" columns from the 'categories_data' DataFrame as per the requirements
    categories_data_final=categories_data[["id","name"]]

    #printing the intial five rows using head() function
    # categories_data_final.head()

    return categories_data_final

"""# function to create annotation inner dictionary"""

def annotation_inner_dict(annotations_data_final,categories_data_final):
    #Merging the 'annotation_data_final' DataFrame and 'categories_data_final' DataFrame on columns "category_id" and "id" respectively from both DataFrame
    #The purpose of this merge is to get the category name
    annotation_inner_dict=pd.merge(left=annotations_data_final,right=categories_data_final,left_on="category_id",right_on="id")

    #printing the intial five rows using head() function
    annotation_inner_dict.head()

    #Finally extracting the "image_id","bbox",and "name" columns as per the requirements
    annotation_inner_dict_final=annotation_inner_dict[["image_id","bbox","name"]]

    #printing the intial five rows using head() function
    # annotation_inner_dict_final.head()

    return annotation_inner_dict_final

"""# function to create final DataFrame"""

def data_fianl(images_data_final,annotation_inner_dict_final):
    #Merging the 'images_data_final' DataFrame and 'annotation_inner_dict_final' DataFrame on columns "id" and "image_id" respectively from both DataFrame
    #The purpose of this merge is to get the annotation data with respect to image_id
    data_final_1=pd.merge(left=images_data_final,right=annotation_inner_dict_final,left_on="id",right_on="image_id")

    #printing the intial five rows using head() function
    # data_final_1.head()

    #Extracting the "id", "file_name", 'name' and 'bbox' columns from the 'data_final_1' DataFrame as per the requirements
    data_final=data_final_1[["id","file_name","name","bbox"]]

    #printing the intial five rows using head() function
    # data_final.head()

    #Renaming the 'name' column to 'category' column as per requirements
    data_final.rename({"name":"category"}, axis=1, inplace=True)

    #printing the intial five rows using head() function
    # data_final.head()

    return data_final

"""# function to group the 'id' and 'file_name' columns"""

def grouping_id_name(data_final):
    #Using pandas groupby function to group the 'category' and 'bbox' columns and renaming the column to "annotations"
    '''to_dict('r') method is used to convert a DataFrame into a list of dictionaries, where each dictionary represents 
    a row of the DataFrame. Here, the 'r' parameter specifies that the conversion should be done row-wise'''

    final_result=data_final.groupby(['id','file_name'])['category','bbox'].apply(lambda x: x.to_dict('r')).reset_index(name='annotations')
    # final_result.head()

    return final_result

"""# Writing the formatted json data to a file"""

def writing_json_file(final_result):
    #Defining an empty dictionary which will have final data
    json_final={}

    #First converting the final_result to json format using 'to_json" then using json.loads to parse the data into json format, this will create a dictionary
    json_final["images"]=json.loads(final_result.to_json(orient='records'))

    #Converting the data to python object using json.demps(), using 'indent=4' for pretty-printing 
    formatted_json_data=json.dumps(json_final,indent=4)

    #Writing the 
    with open('/content/drive/MyDrive/Onelearn_Data_Science_Course/test_check_final.json','w') as f:
        f.write(f"{formatted_json_data}")
    return json_final

"""# Main function to generate the output"""

import warnings
warnings.simplefilter(action='ignore')
import json
import pandas as pd
import warnings

def main(file_path):
    final_data=read_file(file_path)
    images_data_final=images_data(final_data)
    annotations_data_final=annotation_data(final_data)
    categories_data_final=categories_data(final_data)
    annotation_inner_dict_final=annotation_inner_dict(annotations_data_final,categories_data_final)
    data_final=data_fianl(images_data_final,annotation_inner_dict_final)
    final_result=grouping_id_name(data_final)
    json_final=writing_json_file(final_result)
    return json_final

"""# Testing the script on a sample file"""

json_sample_check=main('/content/drive/MyDrive/Onelearn_Data_Science_Course/sample_to_analyse.json')
json_sample_check

"""# Running the script on entire COCO dataset and output the result to a JSON file."""

result_json_file=main('/content/drive/MyDrive/Onelearn_Data_Science_Course/instances_val2017.json')
result_json_file

"""# Reading back the json file for validation

**Validation Report**
* Validation of the output JSON file can be done using jsonschema library
* jsonschema library can be installed in the colab using !pip install jsonschema (If not already installed)
* In order to use the jsonschema for validation purpose, a schema.json file is created which contains the structure of the json
* We can read both the file (JSON file created and scheme file) and load them to separate variables
* Then we can use jsonschema.validate(instance,schema) to validate the structure
* If the structure matches, the validation will pass silently else it raises a "jsonschema.exceptions.ValidationError" exception
* In present case it passes silently means structure matches, and validation was successful
"""

#Reading the file again for the validation purpose
with open('/content/drive/MyDrive/Onelearn_Data_Science_Course/test_check_final.json','r') as f:
    data_new=f.read()

validation_data=json.loads(data_new)

import jsonschema

#Reading the json schema file that defines the specified structure of the JSON
with open('/content/drive/MyDrive/Onelearn_Data_Science_Course/schema.json','r') as f:
    json_schema = json.load(f)

#Verifying if a JSON object conforms to a predefined structure and data type constraints defined by a JSON schema
#If the structure matches, the validation will pass silently

'''If the validations fails, means instance fails to meet the requirements specified in the json_schema,
jsonschema.validate() raises a "jsonschema.exceptions.ValidationError" exception'''

jsonschema.validate(instance=validation_data, schema=json_schema)

